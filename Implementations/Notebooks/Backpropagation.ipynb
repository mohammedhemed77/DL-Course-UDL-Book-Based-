{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrTJg4ULQY5kTvoz9nz9z4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammedhemed77/DL-Course-UDL-Book-Based-/blob/main/Implementations/Notebooks/Backpropagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### üöÄüöÄ Building abstract NN from scratch\n",
        "This code is based on Chapter 2 of Michael Nielsen's interactive book Neural Networks and Deep Learning.\n",
        "\n",
        " I have updated it to use PyTorch instead of NumPy and rewritten it for Python 3.\n",
        "\n",
        "\n",
        "#### By ENG / Mohammed Hemed"
      ],
      "metadata": {
        "id": "AcYyUQ-SHfQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries"
      ],
      "metadata": {
        "id": "g7gVa96eH_rL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "KEIYJfjyE4UI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üî• Neural Network Example: Why Compute ‚àÇL/‚àÇL in Backpropagation?\n",
        "Let's use a simple neural network to classify even vs. odd numbers.\n",
        "We'll use PyTorch and see what happens when we remove ‚àÇL/‚àÇL.\n"
      ],
      "metadata": {
        "id": "D7gXGZ1d5bTW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úÖ Correct Way: Using Backprop Properly"
      ],
      "metadata": {
        "id": "RBiqv6zT6mav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Example Dataset: Even (0) vs. Odd (1)\n",
        "X_train = torch.tensor([[2.0], [4.0], [6.0], [1.0], [3.0], [5.0]])  # Input numbers\n",
        "y_train = torch.tensor([[0.0], [0.0], [0.0], [1.0], [1.0], [1.0]])  # Labels (0 for even, 1 for odd)\n",
        "\n",
        "# Simple Neural Network (1 hidden layer)\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(1, 4)  # 1 input ‚Üí 4 hidden units\n",
        "        self.fc2 = nn.Linear(4, 1)  # 4 hidden ‚Üí 1 output\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.sigmoid(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "# Model, Loss, Optimizer\n",
        "model = SimpleNN()\n",
        "criterion = nn.BCELoss()  # Mean Squared Error Loss (for binary classification)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# Training Loop\n",
        "epochs = 1000\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()         # Reset gradients\n",
        "    y_pred = model(X_train)       # Forward pass\n",
        "    loss = criterion(y_pred, y_train)  # Compute loss\n",
        "    loss.backward()               # Backward pass (compute gradients)\n",
        "    optimizer.step()              # Update weights\n",
        "\n",
        "    if epoch % 100 == 0:  # Print loss every 100 epochs\n",
        "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBvtyy1M5ZFp",
        "outputId": "42a82388-3267-47e4-8024-32f3971ea501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.7386\n",
            "Epoch 100, Loss: 0.6813\n",
            "Epoch 200, Loss: 0.6767\n",
            "Epoch 300, Loss: 0.6721\n",
            "Epoch 400, Loss: 0.6680\n",
            "Epoch 500, Loss: 0.6646\n",
            "Epoch 600, Loss: 0.6617\n",
            "Epoch 700, Loss: 0.6593\n",
            "Epoch 800, Loss: 0.6574\n",
            "Epoch 900, Loss: 0.6559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚ùå Incorrect Way: Detaching the Loss (Breaking Backpropagation)"
      ],
      "metadata": {
        "id": "V3IRt6wq6udm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detaching the loss (breaking the computation graph)\n",
        "loss = loss.detach()\n",
        "\n",
        "# Trying to compute gradients\n",
        "try:\n",
        "    loss.backward()\n",
        "except RuntimeError as e:\n",
        "    print(\"Error:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDU5D2me6011",
        "outputId": "3f3cfc84-504b-4063-bcd1-e44960d854fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: element 0 of tensors does not require grad and does not have a grad_fn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### zip function in python  \n",
        "The zip() function returns a zip object, which is an iterator of tuples where the first item in each passed iterator is paired together, and then the second item in each passed iterator are paired together etc.\n",
        "\n",
        "If the passed iterables have different lengths, the iterable with the shortest items decides the length of the new iterator."
      ],
      "metadata": {
        "id": "_7j7PTLrWE2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = [0.2, 0.5, 0.8]\n",
        "biases = [0.1, 0.3, 0.6]\n",
        "\n",
        "for w, b in zip(weights, biases):\n",
        "    print(f\"Weight: {w}, Bias: {b}\")\n",
        "\n",
        "\n",
        "sizes = [1 , 3 , 5 , 7 , 9]\n",
        "\n",
        "print(sizes[1:])\n",
        "print(sizes[:-1])\n",
        "\n",
        "for size in zip(sizes[:-1], sizes[1:]):\n",
        "    print(size)\n",
        "\n"
      ],
      "metadata": {
        "id": "hW_fXk0OpOzY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dbc072b-544b-43a0-810b-ab83455f3025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight: 0.2, Bias: 0.1\n",
            "Weight: 0.5, Bias: 0.3\n",
            "Weight: 0.8, Bias: 0.6\n",
            "[3, 5, 7, 9]\n",
            "[1, 3, 5, 7]\n",
            "(1, 3)\n",
            "(3, 5)\n",
            "(5, 7)\n",
            "(7, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define our class\n"
      ],
      "metadata": {
        "id": "SLlsMNR2IFU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Network:\n",
        "    def __init__(self, sizes):\n",
        "        \"\"\"Initialize a feedforward neural network with `sizes` representing the number of neurons per layer.\"\"\"\n",
        "\n",
        "        self.num_layers = len(sizes)\n",
        "        self.sizes = sizes\n",
        "\n",
        "        ''' These two lines create lists of tensors, where each element in\n",
        "        the list is a tensor represents the biases or weights for a specific layer in your neural network '''\n",
        "        # Initialize the network with random weights and zero biases\n",
        "\n",
        "        self.biases = [torch.zeros(y, 1) for y in sizes[1:]]  # Biases initialized as zeros\n",
        "        self.weights = [torch.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]  # Heuristic: N(0,1)\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        \"\"\"Sigmoid activation function.\"\"\"\n",
        "        return 1 / (1 + torch.exp(-z))\n",
        "\n",
        "    def sigmoid_prime(self, z):\n",
        "        # Derivative of the sigmoid function\n",
        "        return self.sigmoid(z) * (1 - self.sigmoid(z))\n",
        "\n",
        "    def feedforward(self, a):\n",
        "         # Return the output of the network given input (a)\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            a = self.sigmoid(w @ a + b)\n",
        "        return a\n",
        "\n",
        "    def SGD(self, training_data, epochs, mini_batch_size, lr):\n",
        "            # Train the network using mini-batch stochastic gradient descent\n",
        "        for epoch in range(epochs):\n",
        "            # shuffling dataset every epoch to help model generalize better\n",
        "            random.shuffle(training_data)\n",
        "            # slicing dataset into mini-batces\n",
        "            mini_batches = [training_data[k:k+mini_batch_size] for k in range(0, len(training_data), mini_batch_size)]\n",
        "            for mini_batch in mini_batches:\n",
        "                # update parameters of each batch\n",
        "                self.update_mini_batch(mini_batch, lr)\n",
        "            print(f\"Epoch {epoch+1} complete\")\n",
        "\n",
        "    def update_mini_batch(self, mini_batch, lr):\n",
        "        # Update the network‚Äôs weights and biases by applying gradient descent using backpropagation to a single mini batch.\n",
        "\n",
        "        # these two lines are equivalent to zero_grad in pytorch\n",
        "        # Two list of tensors one for weights - the other for bias\n",
        "        nabla_b = [torch.zeros_like(b) for b in self.biases]      # each element is the same shape as Weights tensor in a given layer\n",
        "        nabla_w = [torch.zeros_like(w) for w in self.weights]     # each element is the same shape as bias tensor in a given layer\n",
        "\n",
        "        for x, y in mini_batch:\n",
        "            # gradients computed by BP for each example\n",
        "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
        "            nabla_b = [nb + dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
        "            nabla_w = [nw + dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
        "\n",
        "        # update Weights and biases after one mini-batch\n",
        "        self.weights = [w - (lr / len(mini_batch)) * nw for w, nw in zip(self.weights, nabla_w)]\n",
        "        self.biases = [b - (lr / len(mini_batch)) * nb for b, nb in zip(self.biases, nabla_b)]\n",
        "\n",
        "    # cheeck shapes for debuguing\n",
        "    def print_shapes(self):\n",
        "        print(\"Biases:\")\n",
        "        for b in self.biases:\n",
        "            print(b.shape)\n",
        "        print(\"\\nWeights:\")\n",
        "        for w in self.weights:\n",
        "            print(w.shape)\n",
        "\n",
        "\n",
        "    def backprop(self, x, y):\n",
        "        # Return a tuple `(nabla_b, nabla_w)` representing the gradient for the cost function.\"\"\"\n",
        "\n",
        "        # This two lines are equivalent to zero_grad in pythoch\n",
        "        nabla_b = [torch.zeros_like(b) for b in self.biases]\n",
        "        nabla_w = [torch.zeros_like(w) for w in self.weights]\n",
        "\n",
        "        # Forward pass\n",
        "        activation = x\n",
        "        activations = [x]  # Store activations layer by layer\n",
        "        zs = []  # Store weighted inputs layer by layer\n",
        "\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            z = w @ activation + b\n",
        "            zs.append(z)\n",
        "            activation = self.sigmoid(z)\n",
        "            activations.append(activation)\n",
        "\n",
        "        # Backward pass\n",
        "        delta = (activations[-1] - y) * self.sigmoid_prime(zs[-1])  # Output layer error\n",
        "        nabla_b[-1] = delta\n",
        "        nabla_w[-1] = delta @ activations[-2].T\n",
        "\n",
        "        for l in range(2, self.num_layers):\n",
        "            z = zs[-l]\n",
        "            sp = self.sigmoid_prime(z)\n",
        "            delta = (self.weights[-l+1].T @ delta) * sp\n",
        "            nabla_b[-l] = delta\n",
        "            nabla_w[-l] = delta @ activations[-l-1].T\n",
        "\n",
        "        return nabla_b, nabla_w\n",
        "\n"
      ],
      "metadata": {
        "id": "F0QX5tETCqFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and prepare our dataset (MNIST)"
      ],
      "metadata": {
        "id": "Xo1XNFdSIQFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.view(-1, 1))  # Flatten 28x28 image to 784x1\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
        "\n",
        "# Convert to list of (image, label) tuples for custom training loop\n",
        "train_data = [(image, torch.nn.functional.one_hot(torch.tensor(label), num_classes=10).float().view(-1, 1))\n",
        "              for image, label in train_dataset]\n",
        "test_data = [(image, label) for image, label in test_dataset]\n"
      ],
      "metadata": {
        "id": "K-VDX9DNFgD3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f0e7b93-78a1-4e4e-ddf2-2ff7a2b34ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.91M/9.91M [00:00<00:00, 124MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28.9k/28.9k [00:00<00:00, 40.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.65M/1.65M [00:00<00:00, 25.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.54k/4.54k [00:00<00:00, 4.71MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define network architecture (784 input neurons, 30 hidden, 10 output)"
      ],
      "metadata": {
        "id": "Jm15GRkKGGAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network = Network([784, 30, 10])\n",
        "network.print_shapes()"
      ],
      "metadata": {
        "id": "dHJVppjtFsw6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb264070-c860-4947-982c-0192e24b5414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Biases:\n",
            "torch.Size([30, 1])\n",
            "torch.Size([10, 1])\n",
            "\n",
            "Weights:\n",
            "torch.Size([30, 784])\n",
            "torch.Size([10, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the network"
      ],
      "metadata": {
        "id": "8bqKOYaHGPb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network.SGD(training_data=train_data, epochs=10, mini_batch_size=32, lr=3.0)"
      ],
      "metadata": {
        "id": "Qm0JGlsqF0FJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bde51a24-dfd5-486f-8602-36bbd9fab229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 complete\n",
            "Epoch 2 complete\n",
            "Epoch 3 complete\n",
            "Epoch 4 complete\n",
            "Epoch 5 complete\n",
            "Epoch 6 complete\n",
            "Epoch 7 complete\n",
            "Epoch 8 complete\n",
            "Epoch 9 complete\n",
            "Epoch 10 complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate on test set"
      ],
      "metadata": {
        "id": "3L79TZ1EGWIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = len(test_data)\n",
        "\n",
        "for image, label in test_data:\n",
        "    output = network.feedforward(image)\n",
        "    predicted = torch.argmax(output).item()\n",
        "    if predicted == label:\n",
        "        correct += 1\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "Wrl8PkmqF9Wo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6738452-016c-4d43-eee5-45dc64c0ade2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 93.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sources :\n",
        "\n",
        "CH2 of NN Nielsen Book : http://neuralnetworksanddeeplearning.com/chap1.html\n",
        "\n",
        "3B1B :\n",
        "https://www.3blue1brown.com/lessons/neural-networks\n",
        "https://www.3blue1brown.com/lessons/gradient-descent\n",
        "https://www.3blue1brown.com/lessons/backpropagation\n",
        "https://www.3blue1brown.com/lessons/backpropagation-calculus\n",
        "\n",
        "DL4CV course Michigan university :\n",
        "Lect6 : (BP) https://youtu.be/dB-u77Y5a6A?si=TjPeCMZh-mz-O2K7\n",
        "\n",
        "CH2 of NN Nielsen Book : http://neuralnetworksanddeeplearning.com/chap1.html"
      ],
      "metadata": {
        "id": "UIRz6-5oFSBU"
      }
    }
  ]
}